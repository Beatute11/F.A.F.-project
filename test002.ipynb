{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd7a90f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.0\n"
     ]
    }
   ],
   "source": [
    "import google.genai\n",
    "print(google.genai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd09ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from flask import Flask, request, jsonify\n",
    "\n",
    "#app = Flask(__name__)\n",
    "\n",
    "#@app.route(\"/\")\n",
    "#def home():\n",
    " #   return \"Home\"\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "   # app.run(debug = True)\n",
    "\n",
    "\n",
    "###########################################\n",
    "from chatbot_logic import get_bot_response\n",
    "\n",
    "def main():\n",
    "    print(\"ðŸ¤– Chatbot is ready. Type 'exit' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        reply = get_bot_response(user_input)\n",
    "        print(f\"Bot: {reply}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00d4be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beata\\anaconda3\\envs\\projektas\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as gen_ai\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gen_ai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "model = gen_ai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "def get_bot_response(prompt: str) -> str:\n",
    "    \"\"\"Generates a response from the Gemini model.\"\"\"\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "110229b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Hello, how can I help you?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "content must not be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mflask\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Flask, request, jsonify\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchatbot_logic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_bot_response\n\u001b[32m      5\u001b[39m app = Flask(\u001b[34m__name__\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;129m@app\u001b[39m.route(\u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhome\u001b[39m():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beata\\Projektelis\\chatbot_logic.py:27\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     23\u001b[39m chat_session = model.start_chat(\n\u001b[32m     24\u001b[39m     history = history\n\u001b[32m     25\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m response = \u001b[43mchat_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m model_response = response.text\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mBot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beata\\anaconda3\\envs\\projektas\\Lib\\site-packages\\google\\generativeai\\generative_models.py:358\u001b[39m, in \u001b[36mChatSession.send_message\u001b[39m\u001b[34m(self, content, generation_config, safety_settings, stream, **kwargs)\u001b[39m\n\u001b[32m    348\u001b[39m \u001b[38;5;129m@string_utils\u001b[39m.set_doc(_SEND_MESSAGE_DOC)\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msend_message\u001b[39m(\n\u001b[32m    350\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    356\u001b[39m     **kwargs,\n\u001b[32m    357\u001b[39m ) -> generation_types.GenerateContentResponse:\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     content = \u001b[43mcontent_types\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content.role:\n\u001b[32m    360\u001b[39m         content.role = \u001b[38;5;28mself\u001b[39m._USER_ROLE\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beata\\anaconda3\\envs\\projektas\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:194\u001b[39m, in \u001b[36mto_content\u001b[39m\u001b[34m(content)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_content\u001b[39m(content: ContentType):\n\u001b[32m    193\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m content:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcontent must not be empty\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content, Mapping):\n\u001b[32m    197\u001b[39m         content = _convert_dict(content)\n",
      "\u001b[31mValueError\u001b[39m: content must not be empty"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "from flask import Flask, request, jsonify\n",
    "from chatbot_logic import get_bot_response\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"Welcome!\"\n",
    "\n",
    "@app.route(\"/chat\", methods=[\"POST\"])\n",
    "def chat():\n",
    "    data = request.json\n",
    "    user_message = data.get(\"message\", \"\")\n",
    "\n",
    "    if not user_message:\n",
    "        return jsonify({\"error\": \"No message provided\"}), 400\n",
    "\n",
    "    bot_reply = get_bot_response(user_message)\n",
    "    return jsonify({\"response\": bot_reply})\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projektas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
